{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f90cfc0",
   "metadata": {},
   "source": [
    "# Transfer learning sur les images : MobileNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de991c68",
   "metadata": {},
   "source": [
    "* import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bf4414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import des librairies\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, time\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D,Dropout, Flatten, Dense, Activation, Input\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from timeit import default_timer as timer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback, ModelCheckpoint, TerminateOnNaN,LearningRateScheduler,TensorBoard\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder # one-hot encoding for age\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB7,ResNet152V2, Xception\n",
    "\n",
    "from random import sample\n",
    "import shutil\n",
    "\n",
    "\n",
    "#import cv2 #import OpenCV -> pip install opencv-python\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1663299b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\admin\\\\Desktop\\\\Data challenge\\\\train_input\\\\train_input\\\\moco_featuresC:\\\\Users\\\\admin\\\\Desktop\\\\Data challenge\\\\train_input\\\\train_input\\\\images'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os #Miscellaneous operating system interfaces\n",
    "#https://docs.python.org/3/library/os.html\n",
    "#get current working directory\n",
    "path = os.getcwd() + 'C:\\\\Users\\\\admin\\\\Desktop\\\\Data challenge\\\\train_input\\\\train_input\\\\images'\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872b511",
   "metadata": {},
   "source": [
    "* Récuperer les données: pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f76ee6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID_001.npy</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_002.npy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_005.npy</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_006.npy</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_007.npy</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Target\n",
       "Sample ID         \n",
       "ID_001.npy       0\n",
       "ID_002.npy       1\n",
       "ID_005.npy       0\n",
       "ID_006.npy       0\n",
       "ID_007.npy       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_output_76GDcgx.csv\", index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8c1095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_path'] = path + df['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e947b6",
   "metadata": {},
   "source": [
    "* Separation des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ea43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['image','prdtypecode']]\n",
    "target = df['prdtypecode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48ceea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img, X_test_img, y_train, y_test = train_test_split(data, target,train_size=0.1,test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d867126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>prdtypecode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48657</th>\n",
       "      <td>image_1151986340_product_2590702548.jpg</td>\n",
       "      <td>2403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22255</th>\n",
       "      <td>image_1104460778_product_1832787442.jpg</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51900</th>\n",
       "      <td>image_1260356330_product_3893244250.jpg</td>\n",
       "      <td>1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51514</th>\n",
       "      <td>image_851402132_product_83232680.jpg</td>\n",
       "      <td>1160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62795</th>\n",
       "      <td>image_1287037647_product_58582799.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27830</th>\n",
       "      <td>image_1314428192_product_4202302602.jpg</td>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27986</th>\n",
       "      <td>image_1319608338_product_4214628106.jpg</td>\n",
       "      <td>2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24537</th>\n",
       "      <td>image_1227217601_product_102678621.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61107</th>\n",
       "      <td>image_892776652_product_140122694.jpg</td>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7106</th>\n",
       "      <td>image_1182180644_product_3005786956.jpg</td>\n",
       "      <td>2522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7485 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image  prdtypecode\n",
       "ID                                                         \n",
       "48657  image_1151986340_product_2590702548.jpg         2403\n",
       "22255  image_1104460778_product_1832787442.jpg         1280\n",
       "51900  image_1260356330_product_3893244250.jpg         1302\n",
       "51514     image_851402132_product_83232680.jpg         1160\n",
       "62795    image_1287037647_product_58582799.jpg           10\n",
       "...                                        ...          ...\n",
       "27830  image_1314428192_product_4202302602.jpg         2585\n",
       "27986  image_1319608338_product_4214628106.jpg         2060\n",
       "24537   image_1227217601_product_102678621.jpg           10\n",
       "61107    image_892776652_product_140122694.jpg         1140\n",
       "7106   image_1182180644_product_3005786956.jpg         2522\n",
       "\n",
       "[7485 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e8887a",
   "metadata": {},
   "source": [
    "* Transformation des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "126f40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img['prdtypecode']=X_train_img['prdtypecode'].astype(str)\n",
    "X_test_img['prdtypecode']=X_test_img['prdtypecode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dab01d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7485 entries, 48657 to 7106\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   image        7485 non-null   object\n",
      " 1   prdtypecode  7485 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 175.4+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train_img.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ce2753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7485 validated image filenames belonging to 27 classes.\n",
      "Found 14971 validated image filenames belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.efficientnet import preprocess_input\n",
    "import tensorflow as tf\n",
    "\n",
    "batch = 32\n",
    "\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n",
    "                                preprocessing_function = preprocess_input,\n",
    "                                   shear_range = 0.5,\n",
    "                                   zoom_range = 0.1,\n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                    brightness_range = [0.9,1.1],\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n",
    "                                                              preprocessing_function = preprocess_input\n",
    "                                                              )\n",
    "\n",
    "train_set = train_datagen.flow_from_dataframe(dataframe=X_train_img,\n",
    "                                              directory=path,\n",
    "                                              x_col = \"image\",\n",
    "                                              y_col = \"prdtypecode\",\n",
    "                                              class_mode =\"sparse\",\n",
    "                                              target_size = (224, 224),\n",
    "                                              batch_size = batch)\n",
    "\n",
    "test_set = test_datagen.flow_from_dataframe(dataframe=X_test_img,\n",
    "                                              directory=path,\n",
    "                                              x_col = \"image\",\n",
    "                                              y_col = \"prdtypecode\",\n",
    "                                            class_mode =\"sparse\",\n",
    "                                              target_size = (224, 224),\n",
    "                                              batch_size = batch,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY SOME TRANSFORMATIONS TO DATA\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "batch = 64\n",
    "\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n",
    "                                preprocessing_function = None,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n",
    "                                                              preprocessing_function = preprocess_input\n",
    "                                                         )\n",
    "\n",
    "\n",
    "\n",
    "train_set = train_datagen.flow_from_dataframe(dataframe=X_train_img,\n",
    "                                              directory=path,\n",
    "                                              x_col = \"image\",\n",
    "                                              y_col = 'prdtypecode',\n",
    "                                              seed=42,\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              target_size = (100, 100),\n",
    "                                              batch_size = batch,\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_set = test_datagen.flow_from_dataframe(dataframe=X_test_img,\n",
    "                                              directory=path,\n",
    "                                              x_col = \"image\",\n",
    "                                              y_col = \"prdtypecode\",\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              seed=42,\n",
    "                                              target_size = (100, 100),\n",
    "                                              batch_size = batch,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946e276",
   "metadata": {},
   "source": [
    "# Callbacks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d409525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "model_type = 'Functional'\n",
    "existing_model = 'efficientNetB1'\n",
    "version = 'v3'\n",
    "filename = model_type + '_' + existing_model + '_' +  version\n",
    "model_path = 'models_output\\\\' + existing_model + '\\\\'\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                         patience=2,\n",
    "                                         mode='max',\n",
    "                                         restore_best_weights=True)\n",
    "\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath= model_path + filename + '.hdf5', \n",
    "                                       monitor='val_accuracy',\n",
    "                                       save_best_only=True,\n",
    "                                       save_weights_only=False,\n",
    "                                       mode='max',\n",
    "                                       save_freq='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebce0fb",
   "metadata": {},
   "source": [
    "#  IMPLEMENTATION DU MODELE :efficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44013044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d839656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "import keras.applications as kapps\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18796267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "basemodel = tf.keras.applications.EfficientNetB1(input_shape = (254, 254, 3),\n",
    "                                              include_top = False,\n",
    "                                              # drop_connect_rate=0.4,\n",
    "                                              weights = 'imagenet')\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(basemodel) \n",
    "\n",
    "model.add(GlobalAveragePooling2D()) \n",
    "\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "\n",
    "model.add(BatchNormalization(trainable = True,axis=1))\n",
    "\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(BatchNormalization(trainable = True,axis=1))\n",
    "\n",
    "\n",
    "model.add(Dense(27, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b28009",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreezed_layers = 10 #Nombre de couches a décongeler pour aplique le finetuning: Voir livre Deep Learning with python\n",
    "\n",
    "# Freezer les couches du efficientNetB1\n",
    "for layer in model.layers: \n",
    "    layer.trainable = False\n",
    "\n",
    "# DeFreezer les quelques couches du VGG16\n",
    "for layer in model.layers[-unfreezed_layers:]: \n",
    "    layer.trainable = True\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4c8e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a17b4017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ridf\\AppData\\Local\\Temp\\ipykernel_8332\\3968565770.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  mobile_model_history = model.fit_generator(train_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "233/233 [==============================] - ETA: 0s - loss: 2.6970 - accuracy: 0.2972"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8332\\3968565770.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m mobile_model_history = model.fit_generator(train_set, \n\u001b[0m\u001b[0;32m      2\u001b[0m                                                   \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                   \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                   \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2602\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2603\u001b[0m         )\n\u001b[1;32m-> 2604\u001b[1;33m         return self.fit(\n\u001b[0m\u001b[0;32m   2605\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2606\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m     return cls(\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[0mskipkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ascii\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
     ]
    }
   ],
   "source": [
    "mobile_model_history = model.fit_generator(train_set, \n",
    "                                                  steps_per_epoch=int(len(y_train.values)/batch),\n",
    "                                                  validation_data = test_set, \n",
    "                                                  validation_steps = int(len(y_test)/batch),\n",
    "                                                  epochs=10, \n",
    "                                                  workers=-1,\n",
    "                                                  callbacks=[early_stopping, checkpoint],\n",
    "                                                  verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286c0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43ebb78e",
   "metadata": {},
   "source": [
    "* Courbe d'évolution model par epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "train_acc = mobile_model_history.history['accuracy']\n",
    "val_acc = mobile_model_history.history['val_accuracy']\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(mobile_model_history.history['loss'])\n",
    "plt.plot(mobile_model_history.history['val_loss'])\n",
    "plt.title('Model loss by epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='right')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(mobile_model_history.history['accuracy'])\n",
    "plt.plot(mobile_model_history.history['val_accuracy'])\n",
    "plt.title('Model acc by epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ef8ac",
   "metadata": {},
   "source": [
    "## Matrice de confusion , Evaluation et Erreurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57423533",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predmobile = mobile_model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c7a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_labels = dict((v,k) for k,v in (train_set.class_indices).items())\n",
    "\n",
    "y_predmobile = [fit_labels[i] for i in np.argmax(y_predmobile, axis=1)]\n",
    "\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e4ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = []\n",
    "for element in y_predmobile:\n",
    "    y_pred1.append(int(element))\n",
    "    \n",
    "y_predmobile=y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a86dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "print(classification_report(y_test,y_predmobile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9f44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt # Pour l'affichage d'images\n",
    "from matplotlib import cm # Pour importer de nouvelles cartes de couleur\n",
    "%matplotlib inline\n",
    "import itertools # Pour créer des iterateurs\n",
    "\n",
    "\n",
    "#Réponse valable:\n",
    "cnf_matrix = metrics.confusion_matrix(y_test,y_predmobile,labels=list(set(y_predmobile)))\n",
    "\n",
    "pond_matrix = []\n",
    "for line in cnf_matrix:\n",
    "    pond_line = []\n",
    "    for cell in line:\n",
    "        pond_line.append(round(cell/sum(line),2))\n",
    "    pond_matrix.append(pond_line)\n",
    "    #print(sum(line))\n",
    "    #print(sum(pond_line))\n",
    "cnf_matrix = np.array(pond_matrix)\n",
    "\n",
    "###Optionnel: Afficher une matrice de confusion sous forme de tableau coloré\n",
    "#classes = range(0,26)\n",
    "classes = set(y_predmobile)\n",
    "\n",
    "plt.figure(figsize=(17,17))\n",
    "\n",
    "plt.imshow(cnf_matrix, interpolation='nearest',cmap='Blues')\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "#tick_marks = set(y_test)\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "    plt.text(j, i, cnf_matrix[i, j],\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cnf_matrix[i, j] > ( cnf_matrix.max() / 2) else \"black\")\n",
    "\n",
    "plt.ylabel('Vrais labels')\n",
    "plt.xlabel('Labels prédits')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8e74f",
   "metadata": {},
   "source": [
    "# Erreurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #import OpenCV\n",
    "import matplotlib.pyplot as plt # Pour l'affichage d'images\n",
    "import matplotlib.pyplot as plt # Pour l'affichage d'images\n",
    "from matplotlib import cm # Pour importer de nouvelles cartes de couleur\n",
    "%matplotlib inline\n",
    "\n",
    "classes = {'10':' Livres, Couvertures de livres ',\n",
    "           '40':' Jeux videos, CDs + mais aussi equipements, cables, etc. ',\n",
    "           '50':' Jeux Vidéos, Equipements ',\n",
    "           '60':' Consoles, Manettes, croix, boutons, ecrans ',\n",
    "           '1140':' Figurines, Personnages et objets, parfois dans des boites ',\n",
    "           '1160':' Cartes, Rectangles, beaucoup de couleurs ',\n",
    "           '1180':' Figurines et boites ',\n",
    "           '1280':' Jouets, poupées nounours, equipements enfants',\n",
    "           '1281':' Jeux enfants, Boites et autres, couleurs flashy',\n",
    "           '1300':' Jeux techniques, Equipement, petites machines ',\n",
    "           '1301':' Habits bébés, petites photos ',\n",
    "           '1302':' Equipements, Habits, outils, jouets, objets sur fond blanc',\n",
    "           '1320':' Matériel et meubles bébé poussettes, habits',\n",
    "           '1560':' Meubles, matelas canapés lampes, chaises',\n",
    "           '1920':' Oreillers, coussins, draps',\n",
    "           '1940':' Alimentations, conserves boites d gateaux',\n",
    "           '2060':' Décorations',\n",
    "           '2220':' Equipements divers pour animaux',\n",
    "           '2280':' Livres et revues anciennes',\n",
    "           '2403':' Livres et revues de collection',\n",
    "           '2462':' Equipement jeux, play stations',\n",
    "           '2522':' Cahiers, carnets, marque pages',\n",
    "           '2582':' Matériel, meubles et outils pour le jardin',\n",
    "           '2583':' Equipements technique pour la maison et exterieur (piscines), produits',\n",
    "           '2585':' Idem 2583:  Equipements technique pour la maison et exterieur (piscines), produits',\n",
    "           '2705':' Livres',\n",
    "           '2905':' Jeux vidéos'}\n",
    "\n",
    "\n",
    "error_indexes = []\n",
    "for i in range(len(y_predmobile)):\n",
    "    if (y_predmobile[i] != y_test[i]):\n",
    "        error_indexes += [i]\n",
    "\n",
    "images = 8\n",
    "        \n",
    "j = 1\n",
    "\n",
    "plt.figure(figsize = (20,20))\n",
    "#plt.subplot(10,5,1)\n",
    "plt.axis('off')\n",
    "\n",
    "for i in np.random.choice(error_indexes, size = images):\n",
    "    img = cv2.imread(path + '\\\\' + X_test_img.iloc[i]['image'])\n",
    "    img = cv2.resize(img, (240, 240), interpolation=cv2.INTER_CUBIC)\n",
    "    #img = cv2.imread(path + '\\\\' + X_test_img.iloc[0]['image_name'], cv2.IMREAD_COLOR)\n",
    "    #img = img.reshape(28, 28)\n",
    "    \n",
    "    #plt.figure(figsize=(5,10))\n",
    "    \n",
    "    plt.subplot(4,2,j)\n",
    "    \n",
    "    #plt.subplot(5, 5, j)\n",
    "    j = j + 1\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=cm.binary, interpolation='None')\n",
    "    plt.title('True Label: ' + classes[str(y_test[i])] \\\n",
    "              + '\\n' + 'Prediction: '+ classes[str(y_predmobile[i])] \\\n",
    "              + '\\n' + 'Confidence: '+ str(round(np.max(y_predmobile, axis=0),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcb5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_model.save('efficientNEtB1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9067a962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d869c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b19c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e6879b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b2bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
